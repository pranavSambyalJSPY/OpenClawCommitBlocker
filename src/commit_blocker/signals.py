"""Signal extraction helpers for commit/PR residue analysis."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
import re
import subprocess
from datetime import datetime


AGENTIC_PATTERNS = [
    re.compile(r"(?i)generated by"),
    re.compile(r"(?i)as an ai"),
    re.compile(r"(?i)automated update"),
    re.compile(r"(?i)co-authored-by:\\s*ai"),
    re.compile(r"(?i)apply patch"),
]

TEMPLATED_SECTION_RE = re.compile(r"(?im)^\s*(summary|testing|notes)\s*[:\-]")
GENERIC_AUTHOR_RE = re.compile(r"(?i)(bot|ai|automation|noreply)")
TODO_TOKEN_RE = re.compile(r"(?i)\b(todo|fixme|tbd|fill this in)\b")


@dataclass(slots=True)
class Signal:
    """A single residue signal and its normalized score."""

    name: str
    score: float
    evidence: str


def _run_git(repo: Path, *args: str) -> str:
    proc = subprocess.run(
        ["git", "-C", str(repo), *args],
        check=False,
        text=True,
        capture_output=True,
    )
    return proc.stdout if proc.returncode == 0 else ""


def _git_available(repo: Path) -> bool:
    return bool(_run_git(repo, "rev-parse", "--git-dir").strip())


def _clamp(value: float) -> float:
    return max(0.0, min(1.0, value))


def _extract_commit_messages(repo: Path, max_commits: int) -> list[str]:
    raw = _run_git(repo, "log", f"-n{max_commits}", "--pretty=format:%B%x1e")
    return [c.strip() for c in raw.split("\x1e") if c.strip()]


def _extract_commit_timestamps(repo: Path, max_commits: int) -> list[datetime]:
    raw = _run_git(repo, "log", f"-n{max_commits}", "--pretty=format:%aI")
    timestamps: list[datetime] = []
    for line in raw.splitlines():
        text = line.strip()
        if not text:
            continue
        timestamps.append(datetime.fromisoformat(text))
    return timestamps


def _extract_authors(repo: Path, max_commits: int) -> list[str]:
    raw = _run_git(repo, "log", f"-n{max_commits}", "--pretty=format:%ae")
    return [line.strip() for line in raw.splitlines() if line.strip()]


def _read_text_files(repo: Path) -> list[str]:
    text_blobs: list[str] = []
    for file_path in repo.rglob("*"):
        if not file_path.is_file() or ".git" in file_path.parts:
            continue
        if file_path.suffix.lower() in {".png", ".jpg", ".jpeg", ".gif", ".pdf", ".zip", ".lock"}:
            continue
        try:
            text_blobs.append(file_path.read_text(encoding="utf-8", errors="ignore"))
        except OSError:
            continue
    return text_blobs


def extract_signals(repo_path: str | Path, max_commits: int = 60) -> list[Signal]:
    """Extract practical residue signals from git history and repository text."""

    repo = Path(repo_path)
    if not repo.exists() or not _git_available(repo):
        return [
            Signal(
                name="repo_unreadable_or_not_git",
                score=1.0,
                evidence="unable_to_read_git_history",
            )
        ]

    messages = _extract_commit_messages(repo, max_commits=max_commits)
    timestamps = _extract_commit_timestamps(repo, max_commits=max_commits)
    authors = _extract_authors(repo, max_commits=max_commits)

    agentic_matches = sum(
        1 for msg in messages if any(pattern.search(msg) for pattern in AGENTIC_PATTERNS)
    )
    agentic_score = _clamp(agentic_matches / max(1, len(messages)))

    templated_matches = sum(1 for msg in messages if len(TEMPLATED_SECTION_RE.findall(msg)) >= 2)
    templated_score = _clamp(templated_matches / max(1, len(messages)))

    unusual_commits = sum(1 for ts in timestamps if ts.hour in {0, 1, 2, 3, 4, 5})
    unusual_hours_score = _clamp(unusual_commits / max(1, len(timestamps)))

    burst_ratio = 0.0
    if len(timestamps) >= 4:
        sorted_ts = sorted(timestamps)
        max_in_window = 1
        left = 0
        for right in range(len(sorted_ts)):
            while (sorted_ts[right] - sorted_ts[left]).total_seconds() > 20 * 60:
                left += 1
            max_in_window = max(max_in_window, right - left + 1)
        burst_ratio = max_in_window / len(sorted_ts)
    burst_score = _clamp(burst_ratio)

    generic_authors = sum(1 for author in authors if GENERIC_AUTHOR_RE.search(author))
    generic_author_score = _clamp(generic_authors / max(1, len(authors)))

    text_blobs = _read_text_files(repo)
    todo_hits = sum(len(TODO_TOKEN_RE.findall(blob)) for blob in text_blobs)
    todo_density = todo_hits / max(1, len(text_blobs))
    todo_score = _clamp(todo_density / 4.0)

    return [
        Signal("message_agentic_phrases", agentic_score, f"matches={agentic_matches}/{len(messages)}"),
        Signal("message_templated_structure", templated_score, f"templated_messages={templated_matches}/{len(messages)}"),
        Signal("commit_unusual_hours", unusual_hours_score, f"unusual_hours={unusual_commits}/{len(timestamps)}"),
        Signal("commit_burst_pattern", burst_score, f"max_20min_burst_ratio={burst_ratio:.2f}"),
        Signal("author_generic_identity", generic_author_score, f"generic_authors={generic_authors}/{len(authors)}"),
        Signal("diff_todo_placeholders", todo_score, f"todo_hits={todo_hits};files_scanned={len(text_blobs)}"),
    ]
